## 1. 下载依赖

```shell
go get -u github.com/gocolly/colly
```


## 2. 相关代码

### 2.1 自定义插件
```go
package extensions

import (
	"bytes"

	"github.com/PuerkitoBio/goquery"
	"github.com/gocolly/colly"
)

func AddGoQuery(c *colly.Collector){
	c.OnResponse(func(r *colly.Response) {
		doc, err := goquery.NewDocumentFromReader(bytes.NewBuffer(r.Body))
		if err != nil {
			r.Ctx.Put("doc", nil)
		}
		r.Ctx.Put("doc", doc)
	})
}
```
> 自动填入 goquery 变量

```go
package extensions

import (
	"github.com/gocolly/colly"
	"github.com/sirupsen/logrus"
)

const MAX_REPEAT_NUM = 5

func RepeatError(c *colly.Collector) {
	c.OnError(func(response *colly.Response, err error) {
		repeatValue := 0
		
		if repeatNum := response.Ctx.GetAny("_repeatNum"); repeatNum != nil {
			repeatValue = repeatNum.(int)
			if repeatValue >= MAX_REPEAT_NUM {
				response.Ctx.Put("_repeatNum", repeatValue + 1)
				logrus.Warnf("丢弃请求[%s] %s", response.Request.URL.String(), err.Error())
				return
			}
		}
		response.Ctx.Put("_repeatNum", repeatValue + 1)
		c.Request(response.Request.Method, response.Request.URL.String(), response.Request.Body, response.Ctx, *response.Request.Headers)
	})
}
```
> 自动重试

### 2.2 定义爬虫逻辑

```go
package spider

import (
	"bytes"
	"crypto/tls"
	"net/http"
	"net/http/cookiejar"
	"net/url"
	"os"
	"strings"
	"time"

	"github.com/PuerkitoBio/goquery"
	"github.com/gocolly/colly"
	log "github.com/sirupsen/logrus"

	"mikan/internal/config"
	"mikan/internal/model"
	"mikan/internal/service/downloader"
	"mikan/internal/spider/extensions"
)

const (
	MikanIndex = "https://mikanani.me"
	LoginUrl   = "https://mikanani.me/Account/Login?ReturnUrl=%2F"
)

type MikanSpider struct {
	Cookie           *cookiejar.Jar
	indexCollector   *colly.Collector
	episodeCollector *colly.Collector
	username         string
	password         string
	Config           config.SpiderConfig
	Downloader       downloader.Downloader
	Logger 		 	 *log.Logger
}

// ParseCookieString 解析 cookie 字符串
func ParseCookieString(config config.SpiderConfig) *cookiejar.Jar {
	cookieJar, _ := cookiejar.New(nil)
	_, err := os.Stat(config.CookiePath)
	if err != nil {
		log.Warnf("获取Cookie失败, 请检查Cookie文件路径是否正确, %v", err)
		return cookieJar
	}
	cookieContent, _ := os.ReadFile(config.CookiePath)
	cookieString := strings.ReplaceAll(string(cookieContent), "\r", "")
	mikanIndexUrl, _ := url.Parse(MikanIndex)
	cookieString = strings.ReplaceAll(strings.TrimSpace(cookieString), "\n", "")
	cookies := strings.Split(cookieString, ";")
	for _, cookie := range cookies {
		cookie = strings.TrimSpace(cookie)
		if cookie == "" {
			continue
		}
		cookiePair := strings.Split(cookie, "=")
		if len(cookiePair) != 2 {
			continue
		}
		cookieJar.SetCookies(mikanIndexUrl, []*http.Cookie{
			{
				Name:  cookiePair[0],
				Value: cookiePair[1],
			},
		})
	}
	return cookieJar
}

// NewMikanSpider 创建 MikanSpider
func NewMikanSpider(config config.SpiderConfig, downloader downloader.Downloader, logger *log.Logger) *MikanSpider {
	cookieJar := ParseCookieString(config)
	mikanSpider := &MikanSpider{
		Cookie:   cookieJar,
		username: config.Username,
		password: config.Password,
		Config:   config,
		Logger:   logger,
	}
	mikanSpider.Downloader = downloader
	c := colly.NewCollector()
	c.WithTransport(&http.Transport{
		TLSClientConfig: &tls.Config{InsecureSkipVerify: true},
	})
	c.AllowURLRevisit = true
	c.Async = true
	c.Limit(&colly.LimitRule{
		DomainGlob:  "*",
		Parallelism: 20,
		RandomDelay: 5 * time.Second,
	})
	indexCollector := c.Clone()
	episodeCollector := c.Clone()
	mikanSpider.indexCollector = indexCollector
	mikanSpider.episodeCollector = episodeCollector
	setCollectors(cookieJar, indexCollector, episodeCollector)
	mikanSpider.scheduleCollector()
	return mikanSpider
}

// 设置自定义扩展
func setCollectors(cookieJar *cookiejar.Jar, c ...*colly.Collector) {
	for _, collector := range c {
		extensions.AddGoQuery(collector)
		extensions.RepeatError(collector)
		collector.SetCookieJar(cookieJar)
	}
}

// 设置爬虫逻辑
func (mikanSpider *MikanSpider) scheduleCollector() {
	// 未登录检测
	mikanSpider.indexCollector.OnResponse(func(r *colly.Response) {
		if r.Request.Ctx.Get("_checkLogin") != "checkLogin" {
			return
		}
		document := r.Request.Ctx.GetAny("doc").(*goquery.Document)
		userName := document.Find("#user-name div.text-right").First().Text()
		if userName == "" {
			mikanSpider.Logger.Infof("未登录,重新登录中...")
			requestVerificationToken, _ := document.Find("input[name='__RequestVerificationToken']").First().Attr("value")
			mikanSpider.login(requestVerificationToken)
		}
		mikanSpider.Logger.Infof("已登录,用户名: %s", userName)
		mikanSpider.ParseMikanIndex(document)
	})
	mikanSpider.indexCollector.OnResponse(func(r *colly.Response) {
		if r.Request.Ctx.Get("_login") != "login" {
			return
		}
		doc := r.Request.Ctx.GetAny("doc").(*goquery.Document)
		userName := doc.Find("#user-name div.text-right").First().Text()
		if userName == "" {
			mikanSpider.Logger.Warnf("登录失败, 请检查用户名密码是否正确")
			return
		}
		mikanSpider.Logger.Infof("登录成功, 用户名: %s", userName)
		cookies := mikanSpider.indexCollector.Cookies(MikanIndex)
		stringBuilder := bytes.Buffer{}
		for _, cookie := range cookies {
			stringBuilder.WriteString(cookie.Name)
			stringBuilder.WriteString("=")
			stringBuilder.WriteString(cookie.Value)
			stringBuilder.WriteString(";")
			stringBuilder.WriteString("\n")
		}
		err := os.WriteFile(mikanSpider.Config.CookiePath, stringBuilder.Bytes(), 0666)
		if err != nil {
			mikanSpider.Logger.Warnf("保存Cookie失败, %v", err)
		}
	})
	// 解析番剧列表
	mikanSpider.episodeCollector.OnResponse(func(r *colly.Response) {
		doc := r.Request.Ctx.GetAny("doc").(*goquery.Document)
		title := r.Request.Ctx.Get("title")
		mikanDate := r.Request.Ctx.Get("mikanDate")
		videoList := []model.Video{}
		mikanSpider.parseEpisode(doc, title, mikanDate, &videoList)
		mikanSpider.Downloader.DownloadVideo(videoList)
	})
}

// 发起登录请求
func (mikanSpider *MikanSpider) login(requestVerificationToken string) {
	ctx := colly.NewContext()
	form := url.Values{}
	ctx.Put("_login", "login")
	form.Add("__RequestVerificationToken", requestVerificationToken)
	form.Add("UserName", mikanSpider.username)
	form.Add("Password", mikanSpider.password)
	form.Add("RememberMe", "true")
	header := http.Header{"Content-Type": {"application/x-www-form-urlencoded"}}
	mikanSpider.indexCollector.Request("POST", LoginUrl, strings.NewReader(form.Encode()), ctx, header)
}

// 解析番剧更新状态
func (mikanSpider MikanSpider) Parse() {
	ctx := colly.NewContext()
	ctx.Put("_checkLogin", "checkLogin")
	mikanSpider.indexCollector.Request("GET", MikanIndex, nil, ctx, nil)
}

```