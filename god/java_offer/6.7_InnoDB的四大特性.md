> 本文摘自-[innodb引擎四大特性](https://www.nasuiyile.cn/219.html)

InnoDB 四大特性

* 预读
* 写缓冲
* 二次写
* 自适应哈希

## 预读

InnoDB 提供缓冲池: 缓存表数据与索引数据,把磁盘上的数据加载到缓冲池,避免每次访问都进行磁盘IO,起到加速访问的作用.

数据库访问通常都遵循集中读取原则,使用一些数据大概率会使用附近的数据,这就是所谓的局部性原理,它表明提前加载是有效的,能减少磁盘的i/o. 预读机制就是发起一个i/o请求,异步的在缓冲池中预先回迁若干个页面,预计将会用到的页面回迁.

>  `Innodb`16kb一页,以64个页为一个 extent ,那么 InnoDB 的预读是以 page 为单位还是以 extent ？

<center><img src="https://ning-wang.oss-cn-beijing.aliyuncs.com/blog-imags/image-20210312111245596.png" alt="image-20210312111245596"  /></center>

数据库请求数据的时候，会将读请求交给文件系统，放入请求队列中；相关进程从请求队列中将读请求取出，根据需求到相关数据区(内存、磁盘)读取数据；取出的数据，放入响应队列中，最后数据库就会从响应队列中将数据取走，完成一次数据读操作过程。

接着进程继续处理请求队列，(如果数据库是全表扫描的话，数据读请求将会占满请求队列)，判断后面几个数据读请求的数据是否相邻，再根据自身系统IO带宽处理量，进行预读，进行读请求的合并处理，一次性读取多块数据放入响应队列中，再被数据库取走。(如此，一次物理读操作，实现多页数据读取，rrqm>0（# iostat -x），假设是4个读请求合并，则rrqm参数显示的就是4)

### 两种预读算法

>  InnoDB使用两种预读算法来提高I/O性能：线性预读（linear read-ahead）和随机预读（randomread-ahead）



#### 线性预读

线性预读方式有一个很重要的变量控制是否将下一个extent预读到buffer pool中，通过使用配置参数innodb_read_ahead_threshold，控制触发innodb执行预读操作的时间。

如果一个 extent 中的被顺序读取的 page 超过或者等于该参数变量时，Innodb 将会异步的将下一个 extent 读取到 buffer pool中，innodb_read_ahead_threshold 可以设置为 0-64 的任何值(因为一个extent中也就只有64页)，默认值为 56，值越高，访问模式检查越严格。

#### ~~随机预读~~

随机预读方式则是表示当同一个extent中的一些page在buffer pool中发现时，Innodb会将该extent中的剩余 page 一并读到buffer pool中。

由于随机预读方式给innodb code带来了一些不必要的复杂性，同时在性能也存在不稳定性，在5.5中已经将这种预读方式废弃，默认是 OFF。若要启用此功能，即将配置变量设置 innodb_random_read_ahead 为 ON 。

## 写缓冲

在MySQL5.5之前，叫插入缓冲(insert buffer)，只针对insert做了优化；现在对delete和update也有效，叫做写缓冲(change buffer)。

它是一种应用在非唯一普通索引页(non-unique secondary index page)不在缓冲池中，对页进行了写操作，并不会立刻将磁盘页加载到缓冲池，而仅仅记录缓冲变更(buffer changes)，等未来数据被读取时，再将数据合并(merge)恢复到缓冲池中的技术。写缓冲的目的是降低写操作的磁盘IO，提升数据库性能。

> 详细介绍-[changebuffer写缓冲](https://www.nasuiyile.cn/209.html#changebuffer%E5%86%99%E7%BC%93%E5%86%B2)

## 二次写

### 脏页刷盘风险

关于IO的最小单位 mysql 最小的io单位是 16k, oracle是8k , 文件系统io最小的单位是 4k(不同的文件系统不一样,也有1k的) .因此存在IO写入导致page损坏的风险



<center><img src="https://ning-wang.oss-cn-beijing.aliyuncs.com/blog-imags/tXNQQH.png" alt="tXNQQH"  /></center>



提高innodb的可靠性, 用来解决部分写失败(partial page write页断裂)

#### 解决的问题

一个数据页的大小是16k,假设在把内存中的脏页写到数据库的时候,写了2k突然掉电,也就是说前2k数据是新的,后14k是旧的,那么磁盘数据库这个数据页就是不完整的,是一个坏掉的数据页.redo只能加上旧,校验完整的数据页恢复一个脏块,不能修复坏掉的数据页,所以这个数据就丢失了,可能会造成数据的不一致,所以需要double write.

#### 使用场景

当数据库正在从内存向磁盘写一个数据页时,数据库宕机,从而导致了这个页只写了部分数据,这就是部分写失效,它会导致数据丢失.这时是无法通过重做日志恢复的,业务重日志记录的只能是页的物理修改,如果页本身已经损坏,重做日志也无能为力.

工作流程如下

<center><img src="https://ning-wang.oss-cn-beijing.aliyuncs.com/blog-imags/tXNtFf.png" alt="tXNtFf"  /></center>

double write 由俩部分组成,一部分为内存中的 double write buffer ,其大小为 2mb ,另一部分是磁盘上共享表空间(idata X)中连续的128个页,即俩个区(exent),大小也就是 2m

- 当一些列机制出发数据缓冲池中的脏页刷新时,并不直接写入磁盘数据文件中,显示拷贝到内存中的 double write buufer 中
- 接着从俩次写入缓冲区分俩次写入磁盘共享表空间中(连续存储,顺序写,性能很高),每次写 1mb ;
- 待第二部完成后,再将 doublewritebuffer 中的脏页数据1写入实际的各个表空间文件(离散写);(脏页数据固话后,即进行标记对于 doblewrite 数据可覆盖)

#### double-wirte 的崩溃恢复

如果操作系统在将页写入磁盘的过程中发生崩溃,在恢复过程中, innodb 存储引擎可以从共享表的空间的doblewrite中找到该页的一个最近副本,将其复制到表空间文件,在应用 redo log ,就完成了恢复过程.

因为有副本所以担心表空间中数据是否损坏

> 为什么写日志不需要 double-write 的支持
>
> 因为 redolog 写入的单位就是512字节,也就是磁盘io的最小单位,所以无所谓数据损

### 副作用

#### double write带来的写负担

double write 是一个buffer,但其实他是在物理文件上的一个buufer,其实也就是file,所以会导致系统有更多的 fsync 操作,而磁盘的fsync性能是很慢的,所以会降低mysql的整体性能

但时 doublewrite buffer 写入磁盘共享表达空间这个过程是连续存储,是顺序写,性能非常高1,牺牲这一点来抱枕该数据也的完整性还是很有必要的

#### 关闭double write适合的场景

海量的增删改

不惧怕系统数据损坏和丢失

系统写负载为主要负载

## 自适应哈希

<center><img src="https://ning-wang.oss-cn-beijing.aliyuncs.com/blog-imags/tXN0yj.png" alt="tXN0yj"  /></center>

Innodb 存储引擎会监控对表上二级索引的查找,如果发现某二级索引被频繁访问,二级索引成为热点数据,建立哈希索引可以带来速度的提升

**特点**

- 无序,没有树高
- 降低对二级索引树的频繁访问资源
- 自适应

**缺陷**

- hash自适应索引会占用innodb buffer pool;
- 自适应hash索引值适合搜索等值查询,如select * from table where index_col='xxx'，而对于其他查找类型，如范围查找，是不能使用的；
- 极端情况下,自适应hash索引才有比较大的意义

**限制**

- 只能用于等值比较,0例如=,<=,>=,in
- 无法用于排序
- 有冲突的可能
- mysql自动管理,无法人为干预