## 缓存的收益和成本

### 受益

1. 加速读写

> * 通过缓存加速读写速度: CPU L1/L2/L3 Cache、Linux page cache加速硬盘读写、浏览器缓存、Ehcache缓存数据库结果

2. 降低后端负载

> * 后端服务器通过前端缓存降低负载： 业务端使用Redis降低后端MySQL负载等

### 成本

1. 数据不一致： 缓存层和数据有时间窗口不一致， 和更新策略有关

2. 代码维护成本： 多了一层缓存逻辑
3. 运维成本： 例如`Redis Cluster`

### 使用场景

1. 降低后端负载

> * 对高消耗的SQL: join结果集/分组统计结果缓存

2. 加速请求响应

> * 利用`Redis`/`Memcache`优化IO响应时间

3. 大量写合并为批量写

> 如计数器先Redis累加在批量写DB



## 缓存更新策略

1. LRU/LFU/FIFO算法剔除: 例如`Reids`中的配置参数`maxmemory-policy`
2. 超时剔除: 例如`expire`
3. 主动更新: 开发控制生命周期

三种策略对比

| 策略             | 一致性 | 维护成本 |
| ---------------- | ------ | -------- |
| LRU/LIRS算法剔除 | 最差   | 低       |
| 超时剔除         | 较差   | 低       |
| 主动更新         | 强     | 高       |
|                  |        |          |

### 建议

1. 低一致性: 最大内存和淘汰策略
2. 高一致性: 超时剔除和主动更新结合, 最大内存和淘汰策略兜底



## 缓存粒度控制

缓存粒度控制从三个角度考虑:

1. 通用性: 全量属性更好
2. 占用空间: 部分属性更好
3. 代码维护: 表面上全面属性更好.

## 缓存穿透优化

> 详细信息参考： [缓存穿透，缓存击穿，缓存雪崩解决方案分析](https://blog.csdn.net/zeb_perfect/article/details/54135506)

缓存穿透的定义如下:

<img src="https://ning-wang.oss-cn-beijing.aliyuncs.com/blog-imags/image-20210204144822115.png" alt="image-20210204144822115" style="zoom:50%;" />

产生原因如下:

1. 业务代码自身问题
2. 恶意攻击、爬虫等

### 解法方法

<center><img src="https://ning-wang.oss-cn-beijing.aliyuncs.com/blog-imags/image-20210204145840658.png" alt="image-20210204145840658" style="zoom: 50%;" /></center>

有很多种方法可以有效地解决缓存穿透问题，最常见的则是采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被 这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。另外也有一个更为简单粗暴的方法（我们采用的就是这种），如果一个查询返回的数据为空（不管是数 据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。

## 缓存无底洞问题优化

> 详细内容参考-[缓存系列文章–无底洞问题](http://ifeve.com/redis-multiget-hole/)

问题的关键点： 更多的机器!=更好的性能

解决方案： 

1. 命令本身优化： 例如查询keys、hgetall bigkey
2. 减少网络通信次数
3. 降低接入成本： 例如客户端长连接/连接池



串行mget: 循环遍历key, 获取结果

<img src="https://ning-wang.oss-cn-beijing.aliyuncs.com/blog-imags/image-20210204151042600.png" alt="image-20210204151042600" style="zoom: 50%;" />

串行IO: 对key预分组, 然后统一进行读取

<img src="https://ning-wang.oss-cn-beijing.aliyuncs.com/blog-imags/image-20210204151117060.png" alt="image-20210204151117060" style="zoom: 50%;" />

并行IO:  在串行IO的基础上, 采用多线程, 优化节点传输时间

<img src="https://ning-wang.oss-cn-beijing.aliyuncs.com/blog-imags/image-20210204151236004.png" alt="image-20210204151236004" style="zoom:50%;" />

hash_tag: 把key强行分配到指定的节点

<img src="https://ning-wang.oss-cn-beijing.aliyuncs.com/blog-imags/image-20210204151427635.png" alt="image-20210204151427635" style="zoom: 50%;" />







<img src="https://ning-wang.oss-cn-beijing.aliyuncs.com/blog-imags/image-20210204150820073.png" alt="image-20210204150820073" style="zoom:50%;" />

## 缓存雪崩优化

缓存雪崩是指在我们设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到DB，DB瞬时压力过重雪崩。



### 解决方案

缓存失效时的雪崩效应对底层系统的冲击非常可怕。大多数系统设计者考虑用加锁或者队列的方式保证缓存的单线 程（进程）写，从而避免失效时大量的并发请求落到底层存储系统上。这里分享一个简单方案就时讲缓存失效时间分散开，比如我们可以在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。

## 缓存击穿

> 详细信息参考： [缓存穿透，缓存击穿，缓存雪崩解决方案分析](https://blog.csdn.net/zeb_perfect/article/details/54135506)

对于一些设置了过期时间的key，如果这些key可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。这个时候，需要考虑一个问题：缓存被“击穿”的问题，这个和缓存雪崩的区别在于这里针对某一key缓存，前者则是很多key。

缓存在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。

解决方案如下

1. 分布式互斥锁

2. 提前使用互斥锁

3. 不过期

4. 资源隔离组件hystrix

   

方案对比如下: 没有最好的方案, 只有最适合的方案

| 解决方案                      | 优点                                                     | 缺点                                                         |
| ----------------------------- | -------------------------------------------------------- | ------------------------------------------------------------ |
| 简单分布式互斥锁（mutex key） | 1. 思路简单  2. 保证一致性                               | 1. 代码复杂度增大  2. 存在死锁的风险  3. 存在线程池阻塞的风险 |
| “提前”使用互斥锁              | 1. 保证一致性                                            | 同上                                                         |
| 不过期(本文)                  | 1. 异步构建缓存，不会阻塞线程池                          | 1. 不保证一致性。  2. 代码复杂度增大(每个value都要维护一个timekey)。  3. 占用一定的内存空间(每个value都要维护一个timekey)。 |
| 资源隔离组件hystrix(本文)     | 1. hystrix技术成熟，有效保证后端。  2. hystrix监控强大。 | 1. 部分访问存在降级策略。                                    |



